{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFRE5s2oer2eoASymDhTGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meloly4/Assignment-2/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag1cuTOUejdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73986988-fd1c-4da2-8223-d20ccb9409f5"
      },
      "source": [
        "!git clone https://github.com/meloly4/Assignment-2.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Assignment-2'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 17 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmIOvjLOUF4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94e2fed-a63e-47fd-b1c4-be223db4d209"
      },
      "source": [
        "!git clone https://github.com/huggingface/neuralcoref.git\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "import spacy\n",
        "\n",
        "%cd neuralcoref\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "\n",
        "import neuralcoref"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'neuralcoref'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 753 (delta 1), reused 2 (delta 0), pack-reused 748\u001b[K\n",
            "Receiving objects: 100% (753/753), 67.82 MiB | 26.84 MiB/s, done.\n",
            "Resolving deltas: 100% (398/398), done.\n",
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/b5/c7a92c7ce5d4b353b70b4b5b4385687206c8b230ddfe08746ab0fd310a3a/spacy-2.3.2-cp36-cp36m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 215kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.4)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Collecting thinc==7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/ae/ef3ae5e93639c0ef8e3eb32e3c18341e511b3c515fcfc603f4b808087651/thinc-7.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.3.2 thinc-7.4.1\n",
            "Collecting en_core_web_lg==2.3.1\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz (782.7MB)\n",
            "\u001b[K     |████████████████████████████████| 782.7MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (50.3.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.4.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.3.1-cp36-none-any.whl size=782936125 sha256=c7b804b6978595e4631fb5acf16cd8ded68f8b3a921493e7511b50121c6db518\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3_4x99_0/wheels/ce/4d/1b/bc6cabb6df139c5f0318927be3ae9e51363fb44d6ea328d3f4\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "/content/neuralcoref\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.3.2)\n",
            "Requirement already satisfied: cython>=0.25 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.29.21)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.6.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (2.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (50.3.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (7.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (1.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 3)) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 3)) (20.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 3)) (8.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 3)) (1.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Obtaining file:///content/neuralcoref\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref==4.0) (1.18.5)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/af/f7a74e19d73ae492fc3171417b4d348fbdff90745867be1f048cd01d7c59/boto3-1.16.22-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref==4.0) (2.23.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref==4.0) (2.3.2)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.22\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/7e/4ac4d23d11e5e0b451cb5fb81e13f11ef5965d27ff9936884c2a6cc91c48/botocore-1.19.22-py2.py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 14.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref==4.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref==4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref==4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref==4.0) (1.24.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (50.3.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (1.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (2.0.4)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref==4.0) (7.4.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.22->boto3->neuralcoref==4.0) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref==4.0) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.22->boto3->neuralcoref==4.0) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref==4.0) (3.4.0)\n",
            "\u001b[31mERROR: botocore 1.19.22 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, neuralcoref\n",
            "  Running setup.py develop for neuralcoref\n",
            "Successfully installed boto3-1.16.22 botocore-1.19.22 jmespath-0.10.0 neuralcoref s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 112 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "100%|██████████| 40155833/40155833 [00:00<00:00, 53680562.51B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBFe8G4zU4XI",
        "outputId": "db7582fa-5c81-4be0-b6c4-14273e7fe585"
      },
      "source": [
        "%cd /content/Assignment-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Assignment-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgYX6dmCGaQe",
        "outputId": "a02e2bdd-fd8b-4a49-d30f-42d6a0c92be5"
      },
      "source": [
        "!python3 chains.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 112 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7uWWtIIG0wv"
      },
      "source": [
        "!python3 example2.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRu8AUAErh1b",
        "outputId": "d83d8571-a6dd-43c7-993b-bcbce9734471"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import pandas as pd\n",
        "import neuralcoref\n",
        "import spacy, json\n",
        "import random, math\n",
        "from collections import namedtuple, Counter, defaultdict as ddict\n",
        "import tqdm\n",
        "from pprint import pprint\n",
        "\n",
        "# Choose your model here\n",
        "# Recall that \"en_core_web_sm\" performed significantly worse with regards to coreference resolution\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "\n",
        "# This is a magic number\n",
        "# When we are computing probabilitieis, we don't want anything to have occurred 0 times because some of our functions are undefined around 9\n",
        "# To avoid 0's, we can use something called Plus One Smoothing, which simply assumes that there is at least a minimum amount of everything\n",
        "# Obviously, this is not the most accurate thing, since there are almost certainly sentences that never have or will be said\n",
        "# But it is very useful for estimating probabilities\n",
        "PLUS_ONE_SMOOTHING = 0.01\n",
        "\n",
        "ParsedStory = namedtuple(\"ParsedStory\", \"id title story one two three four five\".split())\n",
        "\n",
        "def load_data(rocstories):\n",
        "    \"\"\"Loads in rocstories csv file and iterates over the stories\n",
        "    - Returns a generator of stories\n",
        "    - a generator is like a collection/list that isn't populated until a item is requested\n",
        "    - calling a ~next~ function on the generator gives an item if there is one left\n",
        "    - if there are no items left, returns that it is empty\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(rocstories)\n",
        "    return data.itertuples()\n",
        "\n",
        "def parse_story(story):\n",
        "    \"\"\"Take a single story and run it through spacy\"\"\"\n",
        "    name = story.storytitle\n",
        "    # this is very compressed\n",
        "    sentences = [nlp(sentence) for sentence in story[3:]]\n",
        "    full_story = nlp(\" \".join(story[3:]))\n",
        "    return ParsedStory(story.storyid, name, full_story, *sentences)\n",
        "\n",
        "# I've commented out this function to avoid confusion\n",
        "# This was just a demonstration\n",
        "#def parse_story_verbose(story):\n",
        "#    \"\"\"Same as parse_story but this is longer\"\"\"\n",
        "#    name = story.storytitle\n",
        "#    # sentences = [nlp(sentence) for sentence in story[3:]]\n",
        "#    just_story = story[3:]\n",
        "#    sentences = []\n",
        "#    for sentence in just_story:\n",
        "#        sentences.append(nlp(sentence))\n",
        "#    # sentences is a list\n",
        "#    full_story = nlp(\" \".join(story[3:]))\n",
        "#    return ParsedStory(name, full_story, sentences[0], sentences[1], sentences[2], sentences[3], sentences[4])\n",
        "\n",
        "\n",
        "def take_sample(gen, sample=None, replacement=0.2):\n",
        "    if not sample:\n",
        "        \"\"\"If we don't have a sample specified, return the entire generator\"\"\"\n",
        "        return tqdm.tqdm(gen)\n",
        "    # take the first ~sample~ number of stories\n",
        "    # randomly replace stories as we iterate\n",
        "    sentences = []\n",
        "\n",
        "    for x in gen:\n",
        "        sentences.append(x)\n",
        "        if len(sentences) == sample:\n",
        "            break\n",
        "    # sentences has ~sample~ sentences in it\n",
        "    for x in gen:\n",
        "        if random.random() <= replacement:\n",
        "            index = random.randint(1, sample) - 1\n",
        "            sentences[index] = x\n",
        "    return tqdm.tqdm(sentences)\n",
        "\n",
        "def process_corpus(rocstories, sample=None, replacement=0.2):\n",
        "    \"\"\"rocstories is a string with the path to the rocstories.csv file\n",
        "    sample: load a random sample of ~sample~ sentences\n",
        "    \"\"\"\n",
        "    # 1 load the data\n",
        "    # 2 iterate over everything\n",
        "    #   3: parse everything\n",
        "    data = load_data(rocstories)\n",
        "    dataset = [parse_story(story) for story in take_sample(data, sample, replacement)]\n",
        "    story_counter = ddict(list)\n",
        "\n",
        "    for story in dataset:\n",
        "        process_story(story, story_counter=story_counter)\n",
        "\n",
        "    return dataset, ProbabilityTable(story_counter)\n",
        "\n",
        "def process_story(parsedstory, heuristic=2, verbose=False, story_counter=ddict(list)):\n",
        "    prot = protagonist(parsedstory, heuristic=2)\n",
        "    parse_id, dep_pairs = extract_dependency_pairs(parsedstory)\n",
        "\n",
        "    story_counter[parse_id] = dep_pairs\n",
        "\n",
        "    if verbose:\n",
        "        print(\"------------\")\n",
        "        print(\"Protagonist is: \", prot)\n",
        "        print(\"story: \", parsedstory.title)\n",
        "        for sentence in parsedstory[-5:]:\n",
        "            print(sentence)\n",
        "        for entity in dep_pairs:\n",
        "            for d in dep_pairs[entity]:\n",
        "                print(\"\\t\", d)\n",
        "        print(\"------------\")\n",
        "\n",
        "# Return a per-story entity-id for a token\n",
        "def dereference_pair(token, story):\n",
        "    \"\"\"returns a set id for an entity per story\"\"\"\n",
        "    if token.text.lower() in [\"i\", \"me\"]:\n",
        "        return -1\n",
        "    pool = story._.coref_clusters\n",
        "    for ref in pool:\n",
        "        for mention in ref.mentions:\n",
        "            if token == mention.root:\n",
        "                return ref.i\n",
        "    return None\n",
        "\n",
        "#Return a list of dependency pairs\n",
        "def extract_dependency_pairs(parse):\n",
        "    \"\"\"Get a story, return a list of dependency pairs\"\"\"\n",
        "    verbs = [verb for verb in parse.story if verb.pos_ == \"VERB\"]\n",
        "    deps = ddict(list)\n",
        "    for verb in verbs:\n",
        "        for child in verb.children:\n",
        "            entity_index = dereference_pair(child, parse.story)\n",
        "            # Add the word/dependency pair to the identified entity\n",
        "            tup = (verb.lemma_, child.dep_)\n",
        "            if entity_index != None:\n",
        "                deps[entity_index].append(tup)\n",
        "    return parse.id, deps\n",
        "\n",
        "def coreferring_pairs(parse, token):\n",
        "    \"\"\"Because I'm nice, here's a function that gets all the dependency pairs that corefer to the given token\n",
        "    This is inefficiently based on extract_dependency_pairs and dereference_pair for a reason.\n",
        "    \"\"\"\n",
        "    extracted = extract_dependency_pairs(parse)\n",
        "    res = dereference_pair(token, parse.story)\n",
        "    if res is None:\n",
        "        return []\n",
        "    return extracted[res]\n",
        "\n",
        "# Protagonist detection\n",
        "def protagonist(story, heuristic=2):\n",
        "    story = story.story\n",
        "    if heuristic == 1:\n",
        "        return protagonist_heuristic_one(story)\n",
        "    elif heuristic == 2:\n",
        "        return protagonist_heuristic_two(story)\n",
        "    elif heuristic == 3:\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Heuristic 1: first entity\n",
        "def protagonist_heuristic_one(story):\n",
        "    \"\"\"Story is parsed by spacy\"\"\"\n",
        "    return [(story.ents[0].text, 1)]\n",
        "\n",
        "# Heuristic 2: most frequently mentioned entity\n",
        "def protagonist_heuristic_two(story):\n",
        "    #1 get entities\n",
        "    if not story._.coref_clusters:\n",
        "        return None\n",
        "    return max(story._.coref_clusters, key=lambda cluster: len(cluster.mentions))\n",
        "\n",
        "class ProbabilityTable:\n",
        "    def __init__(self, counter):\n",
        "        self.counter = counter\n",
        "        self.cache = {}\n",
        "\n",
        "    def write(self, fname=\"table.json\"):\n",
        "        with open(fname, 'w') as f:\n",
        "            json.dump(self.counter, f, indent=2)\n",
        "\n",
        "    def bigram(self, verb, dependency, verb2, dependency2):\n",
        "        \"\"\"Find all the stories where story contains verb,dependency and verb2,dependency2\n",
        "        AND they refer to the same entity\n",
        "        \"\"\"\n",
        "        query = (verb, dependency, verb2, dependency2)\n",
        "        if query not in self.cache:\n",
        "            ctr = 0\n",
        "            for story in self.counter:\n",
        "                for entity in self.counter[story]:\n",
        "                    v = self.counter[story][entity]\n",
        "                    if [verb, dependency] in v and [verb2, dependency2] in v:\n",
        "                        ctr +=1\n",
        "            self.cache[query] = ctr\n",
        "        return self.cache[query]\n",
        "\n",
        "    def unigram(self, verb, dependency):\n",
        "        \"\"\"Number of stories containing verb/dependency\"\"\"\n",
        "        query = (verb, dependency)\n",
        "        if query not in self.cache:\n",
        "            ctr = 0\n",
        "            for story in self.counter:\n",
        "                for entity in self.counter[story]:\n",
        "                    if [verb, dependency] in self.counter[story][entity]:\n",
        "                        ctr += 1\n",
        "            self.cache[query] = ctr\n",
        "        return self.cache[query]\n",
        "\n",
        "    def pmi(self, verb, dependency, verb2, dependency2):\n",
        "        n = len(self.counter) + PLUS_ONE_SMOOTHING\n",
        "        prob_a_and_b = (self.bigram(verb, dependency, verb2, dependency2)+PLUS_ONE_SMOOTHING)/n\n",
        "        prob_a = (self.unigram(verb, dependency)+PLUS_ONE_SMOOTHING)/n\n",
        "        prob_b = (self.unigram(verb2, dependency2)+PLUS_ONE_SMOOTHING)/n\n",
        "        return math.log(prob_a_and_b/(prob_a*prob_b))\n",
        "        #math.log(prob_a_and_b) - (math.log(prob_a) + math.log(prob_b))\n",
        "\n",
        "    def histo(self, verb, dependency):\n",
        "        \"\"\"Return cooccurrence counts for all verb/dependency pairs for a given verb/dependency\"\"\"\n",
        "        ctr = Counter()\n",
        "        for story in self.counter:\n",
        "            for entity in self.counter[story]:\n",
        "                if (verb, dependency) in self.counter[story][entity]:\n",
        "                    for c in self.counter[story][entity]:\n",
        "                        if c != (verb, dependency):\n",
        "                            ctr[c] += 1\n",
        "        return ctr\n",
        "\n",
        "\n",
        "    def histo_pmi(self, verb, dependency):\n",
        "        return sorted([(v, d, self.pmi(verb, dependency, v, d)) for v, d in self.histo(verb, dependency)], key=lambda x: x[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 112 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG5rY3v3qTY7"
      },
      "source": [
        "import chains\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "def parse_test_instance(story):\n",
        "    \"\"\"Returns TWO ParsedStory instances representing option 1 and 2\"\"\"\n",
        "    # this is very compressed\n",
        "    id = story.InputStoryid\n",
        "    story = list(story)\n",
        "    sentences = [chains.nlp(sentence) for sentence in story[2:6]]\n",
        "    alternatives = [story[6], story[7]]\n",
        "    return [chains.ParsedStory(id, id, chains.nlp(\" \".join(story[2:6]+[a])), *(sentences+[chains.nlp(a)])) for a in alternatives]\n",
        "\n",
        "def story_answer(story):\n",
        "    \"\"\"Tells you the correct answer. Return (storyid, index). 1 for the first ending, 2 for the second ending\"\"\"\n",
        "    #obviously you can't use this information until you've chosen your answer!\n",
        "    return story.InputStoryid\n",
        "\n",
        "# Load training data and build the model\n",
        "# data, table = chains.process_corpus(\"train.csv\", 100)\n",
        "# print(table.pmi(\"move\", \"nsubj\", \"move\", \"nsubj\"))\n",
        "\n",
        "# load the pre-built model\n",
        "with open(\"all.json\") as fp:\n",
        "    table = chains.ProbabilityTable(json.load(fp))\n",
        "\n",
        "# load testing data\n",
        "test = chains.load_data(\"tinytest.csv\")\n",
        "for t in test:\n",
        "    one, two = parse_test_instance(t)\n",
        "    one_deps = chains.extract_dependency_pairs(one)\n",
        "    pprint(one[2:])\n",
        "    pprint(two[2:])\n",
        "    # logic to choose between one and two\n",
        "    pprint(\"answer:\"+ str(story_answer(t)))\n",
        "    # pprint(t[6])\n",
        "    # for key,value in one_deps[1].items():\n",
        "    #   for v in value:\n",
        "        # pprint(table.pmi(v[0],v[1],v[0],v[1]))\n",
        "        # pprint(table.bigram(v[0],v[1],v[0],v[1]))\n",
        "    # pprint(t[7])\n",
        "    # for key,value in two_deps[1].items():\n",
        "    #   for v in value:\n",
        "    #     pprint(v[0])\n",
        "    #     pprint(table.pmi(v[0],v[1],v[0],v[1]))\n",
        "    #     pprint(table.bigram(v[0],v[1],v[0],v[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwZtR-UZsnfz",
        "outputId": "4c2020b1-ddcd-4e37-d355-41a29c9b73cd"
      },
      "source": [
        "import chains\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "def parse_test_instance(story):\n",
        "    \"\"\"Returns TWO ParsedStory instances representing option 1 and 2\"\"\"\n",
        "    # this is very compressed\n",
        "    id = story.InputStoryid\n",
        "    story = list(story)\n",
        "    sentences = [chains.nlp(sentence) for sentence in story[2:6]]\n",
        "    alternatives = [story[6], story[7]]\n",
        "    return [chains.ParsedStory(id, id, chains.nlp(\" \".join(story[2:6]+[a])), *(sentences+[chains.nlp(a)])) for a in alternatives]\n",
        "\n",
        "# def story_answer(story):\n",
        "#     \"\"\"Tells you the correct answer. Return (storyid, index). 1 for the first ending, 2 for the second ending\"\"\"\n",
        "#     #obviously you can't use this information until you've chosen your answer!\n",
        "#     return story.InputStoryid\n",
        "\n",
        "# Load training data and build the model\n",
        "# data, table = chains.process_corpus(\"train.csv\", 100)\n",
        "# print(table.pmi(\"move\", \"nsubj\", \"move\", \"nsubj\"))\n",
        "\n",
        "# load the pre-built model\n",
        "with open(\"all.json\") as fp:\n",
        "    table = chains.ProbabilityTable(json.load(fp))\n",
        "\n",
        "# load testing data\n",
        "test = chains.load_data(\"tinytest.csv\")\n",
        "for t in test:\n",
        "    one, two = parse_test_instance(t)\n",
        "    one_deps = chains.extract_dependency_pairs(one)\n",
        "    two_deps = chains.extract_dependency_pairs(two)\n",
        "    pprint(one_deps)\n",
        "    # pprint(chains.coreferring_pairs(one,protagonist(one).main.root))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('138d5bfb-05cc-41e3-bf2c-fa85ebad14e2',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('grow', 'nsubj'),\n",
            "                  ('find', 'nsubj'),\n",
            "                  ('shoot', 'nsubjpass'),\n",
            "                  ('turn', 'nsubj')]}))\n",
            "('bff9f820-9605-4875-b9af-fe6f14d04256',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('need', 'nsubj'),\n",
            "                  ('decide', 'nsubj'),\n",
            "                  ('choose', 'nsubj'),\n",
            "                  ('test', 'nsubj'),\n",
            "                  ('eat', 'nsubj')],\n",
            "              1: [('choose', 'dobj'), ('follow', 'dobj')]}))\n",
            "('e8f628d5-9f97-40ed-8611-fc0e774673c4',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('dream', 'nsubj'),\n",
            "                  ('save', 'nsubj'),\n",
            "                  ('land', 'nsubj'),\n",
            "                  ('like', 'nsubj'),\n",
            "                  ('decide', 'nsubj')],\n",
            "              1: [('visit', 'dobj')]}))\n",
            "('f5226bfe-9f26-4377-b05f-3d9568dbdec1',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('intend', 'nsubj'), ('like', 'nsubj'), ('eat', 'nsubj')],\n",
            "              2: [('like', 'dobj')]}))\n",
            "('69ac9b05-b956-402f-9fff-1f926ef9176b',\n",
            " defaultdict(<class 'list'>, {-1: [('play', 'nsubj')]}))\n",
            "('d80cabdd-7a85-47e3-86be-5ce6591ca51e',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('find', 'nsubj'),\n",
            "                  ('begin', 'nsubj'),\n",
            "                  ('take', 'nsubj'),\n",
            "                  ('take', 'nsubj')]}))\n",
            "('58090d3f-8a91-4c89-83ef-2b4994de9d24',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('start', 'nsubj'), ('love', 'nsubj'), ('fire', 'nsubjpass')],\n",
            "              1: [('love', 'dobj')],\n",
            "              2: [('tell', 'nsubj'), ('tell', 'dobj')]}))\n",
            "('e17053ac-2046-48c8-a7a2-7b9509c10e64',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('become', 'nsubj'), ('compete', 'nsubj')],\n",
            "              1: [('enter', 'nsubj'), ('win', 'nsubj'), ('send', 'dobj')],\n",
            "              3: [('enter', 'dobj'), ('win', 'dobj')],\n",
            "              4: [('send', 'nsubj')]}))\n",
            "('69b26ae4-b778-4cd1-9f13-27d28fd4430e',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('work', 'nsubj'),\n",
            "                  ('fail', 'nsubj'),\n",
            "                  ('continue', 'nsubj'),\n",
            "                  ('give', 'nsubj')]}))\n",
            "('1f7d9fa2-2191-49de-bdd1-7d307293b9e0',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('hate', 'nsubj'),\n",
            "                  ('convince', 'dobj'),\n",
            "                  ('have', 'nsubj'),\n",
            "                  ('show', 'dobj'),\n",
            "                  ('show', 'dative'),\n",
            "                  ('come', 'nsubj')],\n",
            "              1: [('convince', 'nsubj'), ('show', 'nsubj')]}))\n",
            "('a7905e16-15be-433f-bdef-b488a83e4582',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('arrive', 'nsubj'),\n",
            "                  ('walk', 'nsubj'),\n",
            "                  ('believe', 'nsubj'),\n",
            "                  ('board', 'nsubj'),\n",
            "                  ('enjoy', 'nsubj')],\n",
            "              2: [('leave', 'dobj')]}))\n",
            "('52dbbfda-5b42-4ace-8d59-55cee3eb30c0',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('want', 'nsubj'),\n",
            "                  ('decide', 'nsubj'),\n",
            "                  ('make', 'nsubj'),\n",
            "                  ('win', 'nsubj'),\n",
            "                  ('give', 'nsubj')],\n",
            "              1: [('swim', 'dobj')]}))\n",
            "('1edf348d-6fce-4ea3-937c-28ade02f28b8',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('buy', 'nsubj'),\n",
            "                  ('decide', 'nsubj'),\n",
            "                  ('man', 'nsubj'),\n",
            "                  ('decide', 'nsubj')],\n",
            "              1: [('buy', 'dobj'), ('man', 'dobj')]}))\n",
            "('0fe46de6-6ee3-4932-a578-268917372566',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('receive', 'nsubj'),\n",
            "                  ('love', 'nsubj'),\n",
            "                  ('get', 'nsubj'),\n",
            "                  ('boot', 'nsubj'),\n",
            "                  ('write', 'nsubj'),\n",
            "                  ('know', 'nsubj'),\n",
            "                  ('dislike', 'nsubj')],\n",
            "              1: [('love', 'dobj'), ('dislike', 'dobj')]}))\n",
            "('625d1e13-8bd3-40b3-ac45-0b16a549fc69',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('dream', 'nsubj'),\n",
            "                  ('plan', 'nsubj'),\n",
            "                  ('fertilize', 'nsubj'),\n",
            "                  ('end', 'nsubj')],\n",
            "              1: [('grow', 'nsubj')],\n",
            "              2: [('fertilize', 'dobj'), ('cover', 'dobj')]}))\n",
            "('aa615e4f-83c1-4b65-96a4-6a989d253a52',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('start', 'nsubj'),\n",
            "                  ('try', 'nsubj'),\n",
            "                  ('could', 'nsubj'),\n",
            "                  ('decide', 'nsubj'),\n",
            "                  ('welcome', 'dobj'),\n",
            "                  ('go', 'nsubj')],\n",
            "              1: [('make', 'dobj'), ('welcome', 'nsubj')]}))\n",
            "('fa0d318c-d286-4c8e-adda-c2590f100f02',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('get', 'nsubj'),\n",
            "                  ('like', 'nsubj'),\n",
            "                  ('long', 'nsubj'),\n",
            "                  ('trip', 'nsubj'),\n",
            "                  ('break', 'nsubj'),\n",
            "                  ('go', 'nsubj')]}))\n",
            "('501c6884-8885-4df3-ae8c-f3f9328fde54',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('misplace', 'nsubj'),\n",
            "                  ('grab', 'nsubj'),\n",
            "                  ('want', 'nsubj')]}))\n",
            "('8d9f72c4-7f31-4e86-8511-e921fd8f78bb',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('marry', 'nsubjpass'), ('call', 'nsubj')],\n",
            "              1: [('call', 'nsubj'),\n",
            "                  ('forget', 'nsubj'),\n",
            "                  ('call', 'dobj'),\n",
            "                  ('leave', 'nsubj'),\n",
            "                  ('threaten', 'nsubj'),\n",
            "                  ('call', 'dobj')]}))\n",
            "('ba87797c-dc31-402b-8740-d30c093d4df7',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('love', 'nsubj'),\n",
            "                  ('see', 'nsubj'),\n",
            "                  ('win', 'nsubj'),\n",
            "                  ('choose', 'nsubj'),\n",
            "                  ('continue', 'nsubj')]}))\n",
            "('384621a9-d9b6-436d-8914-61a93d916015',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('ask', 'nsubjpass'),\n",
            "                  ('go', 'nsubj'),\n",
            "                  ('shoot', 'nsubj'),\n",
            "                  ('love', 'nsubj'),\n",
            "                  ('plan', 'nsubj')]}))\n",
            "('f531b039-67a6-4797-989d-24f716ed4073',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('decide', 'nsubj')],\n",
            "              1: [('use', 'nsubj'),\n",
            "                  ('decide', 'nsubj'),\n",
            "                  ('love', 'nsubj'),\n",
            "                  ('go', 'nsubj')]}))\n",
            "('60facd71-c194-427a-9127-471d5844785e',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('decide', 'nsubj'),\n",
            "                  ('receive', 'nsubj'),\n",
            "                  ('see', 'nsubj'),\n",
            "                  ('tell', 'dobj'),\n",
            "                  ('break', 'nsubj')],\n",
            "              1: [('tell', 'nsubj')]}))\n",
            "('d4aff04b-ba93-4cff-8b35-7eb10dd9e23f',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('watch', 'nsubj'), ('start', 'nsubj')],\n",
            "              1: [('chase', 'nsubj'), ('catch', 'nsubj')],\n",
            "              2: [('chase', 'dobj'), ('catch', 'dobj')]}))\n",
            "('8db8ec1c-1d94-4f9d-b71d-3b533e30a1c5',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('love', 'nsubj'),\n",
            "                  ('match', 'nsubj'),\n",
            "                  ('gain', 'nsubj'),\n",
            "                  ('go', 'nsubj')],\n",
            "              1: [('match', 'dobj'), ('become', 'nsubj')]}))\n",
            "('696b1a71-b684-45ec-8435-7b48274ee411',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('buy', 'nsubj'),\n",
            "                  ('try', 'nsubj'),\n",
            "                  ('drop', 'nsubj'),\n",
            "                  ('hurt', 'nsubj'),\n",
            "                  ('love', 'nsubj')],\n",
            "              1: [('ride', 'dobj'), ('drop', 'dobj')]}))\n",
            "('1d14ed7d-5a05-476b-bfab-3e3568a0dd6b',\n",
            " defaultdict(<class 'list'>,\n",
            "             {-1: [('go', 'nsubj')],\n",
            "              0: [('set', 'nsubjpass'), ('seem', 'nsubj')]}))\n",
            "('9f32f9ef-0b7b-461b-953f-3d7da39bac87',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('need', 'nsubj'), ('put', 'nsubj'), ('try', 'nsubj')],\n",
            "              1: [('crush', 'dobj'), ('put', 'dobj'), ('crush', 'dobj')]}))\n",
            "('3972aeda-e5f8-4776-abbb-8566bf38930a',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('drive', 'nsubj'),\n",
            "                  ('party', 'nsubj'),\n",
            "                  ('know', 'nsubj'),\n",
            "                  ('swerve', 'nsubj')]}))\n",
            "('411b9523-5254-41ff-b740-e039d0423201',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('grow', 'nsubj'),\n",
            "                  ('bring', 'nsubj'),\n",
            "                  ('cook', 'nsubj'),\n",
            "                  ('add', 'nsubj'),\n",
            "                  ('think', 'nsubj'),\n",
            "                  ('eat', 'nsubj')],\n",
            "              2: [('bring', 'dobj'), ('shell', 'dobj'), ('cook', 'dobj')],\n",
            "              3: [('make', 'dobj'), ('eat', 'dobj')]}))\n",
            "('36b638c3-f2d1-44dc-bab1-5bf2a9d7fdff',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('bind', 'nsubjpass'),\n",
            "                  ('decide', 'nsubj'),\n",
            "                  ('find', 'nsubj'),\n",
            "                  ('contact', 'nsubj')],\n",
            "              1: [('move', 'nsubj'),\n",
            "                  ('find', 'dobj'),\n",
            "                  ('find', 'dobj'),\n",
            "                  ('contact', 'dobj')]}))\n",
            "('80b6447f-4c37-4194-9862-3785e5075463',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('go', 'nsubj'), ('watch', 'nsubj'), ('know', 'nsubj')],\n",
            "              1: [('add', 'nsubj'), ('stretch', 'nsubj'), ('shape', 'nsubj')],\n",
            "              2: [('stretch', 'dobj'), ('shape', 'dobj'), ('cool', 'nsubj')]}))\n",
            "('dd3506fe-31ce-4bbb-9000-02c222da3466',\n",
            " defaultdict(<class 'list'>,\n",
            "             {-1: [('move', 'nsubj'),\n",
            "                   ('know', 'nsubj'),\n",
            "                   ('find', 'nsubj'),\n",
            "                   ('feel', 'nsubj'),\n",
            "                   ('grab', 'nsubj')],\n",
            "              0: [('know', 'dobj'), ('meet', 'dobj')],\n",
            "              1: [('grab', 'dobj'), ('return', 'dobj')]}))\n",
            "('ad42188e-383b-4c7d-9cd9-906725b7ce12',\n",
            " defaultdict(<class 'list'>,\n",
            "             {0: [('study', 'nsubj'),\n",
            "                  ('wait', 'nsubj'),\n",
            "                  ('sleep', 'nsubj'),\n",
            "                  ('get', 'nsubj'),\n",
            "                  ('exhaust', 'nsubjpass')]}))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}